{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86bc5cce-c20d-4936-9da5-e68aa381f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing modules\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as df\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.signal import freqz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6640fbc4-4d97-4630-92d5-7fe63ee98ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0101T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 604802  =      0.000 ...  2419.208 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0103T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 469010  =      0.000 ...  1876.040 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0201T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 604802  =      0.000 ...  2419.208 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0202T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 604802  =      0.000 ...  2419.208 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0203T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 464154  =      0.000 ...  1856.616 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0301T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 604802  =      0.000 ...  2419.208 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0302T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 604802  =      0.000 ...  2419.208 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0303T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 464674  =      0.000 ...  1858.696 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0401T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 604802  =      0.000 ...  2419.208 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0402T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 696265  =      0.000 ...  2785.060 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0403T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 468558  =      0.000 ...  1874.232 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0501T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 604802  =      0.000 ...  2419.208 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0502T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 696265  =      0.000 ...  2785.060 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0503T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 461874  =      0.000 ...  1847.496 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0601T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 604802  =      0.000 ...  2419.208 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0602T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 604802  =      0.000 ...  2419.208 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0603T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 470390  =      0.000 ...  1881.560 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0701T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 604802  =      0.000 ...  2419.208 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0702T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 604802  =      0.000 ...  2419.208 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0703T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 466726  =      0.000 ...  1866.904 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0801T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 787728  =      0.000 ...  3150.912 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0802T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 604802  =      0.000 ...  2419.208 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0803T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 474834  =      0.000 ...  1899.336 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0901T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 604802  =      0.000 ...  2419.208 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0902T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 604802  =      0.000 ...  2419.208 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Lenovo\\Desktop\\JU\\2b_dataset\\B0903T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG:C3, EEG:Cz, EEG:C4\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 460730  =      0.000 ...  1842.920 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12704\\2529578853.py:35: RuntimeWarning: Highpass cutoff frequency 100.0 is greater than lowpass cutoff frequency 0.5, setting values to 0 and Nyquist.\n",
      "  raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n"
     ]
    }
   ],
   "source": [
    "#dropping the eog channels as we will be working only on 22 eeg channels\n",
    "file_paths_1 = [\n",
    "    'B0101T.gdf',\n",
    "    \n",
    "    'B0103T.gdf',\n",
    "    'B0201T.gdf',\n",
    "    'B0202T.gdf',\n",
    "    'B0203T.gdf',\n",
    "    'B0301T.gdf',\n",
    "    'B0302T.gdf',\n",
    "    'B0303T.gdf',\n",
    "    'B0401T.gdf',\n",
    "    'B0402T.gdf',\n",
    "    'B0403T.gdf',\n",
    "    'B0501T.gdf',\n",
    "    'B0502T.gdf',\n",
    "    'B0503T.gdf',\n",
    "    'B0601T.gdf',\n",
    "    'B0602T.gdf',\n",
    "    'B0603T.gdf',\n",
    "    'B0701T.gdf',\n",
    "    'B0702T.gdf',\n",
    "    'B0703T.gdf',\n",
    "    'B0801T.gdf',\n",
    "    'B0802T.gdf',\n",
    "    'B0803T.gdf',\n",
    "    'B0901T.gdf',\n",
    "    'B0902T.gdf',\n",
    "    'B0903T.gdf'\n",
    "]\n",
    "\n",
    "raw = []\n",
    "\n",
    "for file_path in file_paths_1:\n",
    "    raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n",
    "    \n",
    "    p=raw_data.drop_channels(['EOG:ch01', 'EOG:ch02', 'EOG:ch03'])\n",
    "    raw.append(p)\n",
    "    \n",
    "#This file has no EOG channel\n",
    "#raw_data1 =mne.io.read_raw_gdf(\"B0102T.gdf\")\n",
    "#raw.append(raw_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f54b6aa-abe4-46b4-98ea-4594f05b399c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>December 09, 2005  09:20:50 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>Not available</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>3 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>125.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "</table>"
      ],
      "text/plain": [
       "<Info | 7 non-empty values\n",
       " bads: []\n",
       " ch_names: EEG:C3, EEG:Cz, EEG:C4\n",
       " chs: 3 EEG\n",
       " custom_ref_applied: False\n",
       " highpass: 0.0 Hz\n",
       " lowpass: 125.0 Hz\n",
       " meas_date: 2005-12-09 09:20:50 UTC\n",
       " nchan: 3\n",
       " projs: []\n",
       " sfreq: 250.0 Hz\n",
       ">"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[25].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "053fbd05-3efa-4e6d-bb00-44e752fac230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770', '781']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770', '781']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770', '781']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770', '781']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770', '781']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770', '781']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770', '781']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770', '781']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770']\n",
      "Used Annotations descriptions: ['1023', '1077', '1078', '1079', '1081', '276', '277', '32766', '768', '769', '770', '781']\n"
     ]
    }
   ],
   "source": [
    "#Annotation object for annotating segments of raw data.\n",
    "for i in range(0,26):\n",
    "    raw[i].annotations\n",
    "    events=mne.events_from_annotations(raw[i])\n",
    "    #printing the 1st index of the events which contains the overall details of the file\n",
    "    events[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcdc4162-8a68-4612-ad0a-75c73447384d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     8],\n",
       "       [  499,     0,     6],\n",
       "       [16749,     0,     7],\n",
       "       [32999,     0,     5],\n",
       "       [37999,     0,     4],\n",
       "       [42999,     0,     3],\n",
       "       [47999,     0,     2],\n",
       "       [52251,     0,     8],\n",
       "       [54349,     0,     9],\n",
       "       [55099,     0,    11],\n",
       "       [55224,     0,    12],\n",
       "       [56938,     0,     9],\n",
       "       [56938,     0,     1],\n",
       "       [57688,     0,    10],\n",
       "       [57813,     0,    12],\n",
       "       [59516,     0,     9],\n",
       "       [60266,     0,    10],\n",
       "       [60391,     0,    12],\n",
       "       [61822,     0,     9],\n",
       "       [62572,     0,    11]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#events[0] contains the main data in which we should work on \n",
    "events[0][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e23e287c-a528-4cbb-80d9-490e479633cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a event dictionary\n",
    "event_dict={\n",
    " 'rejected trial':1,\n",
    " 'horizontal eye movement':2,\n",
    " 'vertical eye movement':3,\n",
    " 'eye rotation':4,\n",
    " 'eye blinks':5,\n",
    " 'eye open':6,\n",
    " 'eye close':7,\n",
    " 'start of a new run':8,\n",
    " 'start of a trial':9,\n",
    " 'class 1':10,\n",
    " 'class 2':11,\n",
    " 'BCI feedback':12,\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95693a05-4662-4c75-821d-80864a56a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,26):\n",
    "    rawinfo=raw[i].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c53a8766-0f7d-4bef-a42c-da91280f3ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>December 09, 2005  09:20:50 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>Not available</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>3 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>125.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "</table>"
      ],
      "text/plain": [
       "<Info | 7 non-empty values\n",
       " bads: []\n",
       " ch_names: EEG:C3, EEG:Cz, EEG:C4\n",
       " chs: 3 EEG\n",
       " custom_ref_applied: False\n",
       " highpass: 0.0 Hz\n",
       " lowpass: 125.0 Hz\n",
       " meas_date: 2005-12-09 09:20:50 UTC\n",
       " nchan: 3\n",
       " projs: []\n",
       " sfreq: 250.0 Hz\n",
       ">"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d64e099a-8014-46a7-8825-311670455bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'epochs = mne.Epochs(raw[26], events[0], new_event_id=[4], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\\nclassA26 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\\nclassA= np.append(classA,classA26)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an epoch with tmin=0.0 and set baseline explicitly\n",
    "epochs = mne.Epochs(raw[0], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "# Now you can select the data between 3.0 and 7.5 seconds\n",
    "classA = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data() # 'data_within_range' now contains the EEG data from 3.0 to 7.5 seconds without baseline correction.\n",
    "epochs = mne.Epochs(raw[1], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA1 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA1)\n",
    "epochs = mne.Epochs(raw[2], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA2 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA2)\n",
    "epochs = mne.Epochs(raw[3], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA3 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA3)\n",
    "epochs = mne.Epochs(raw[4], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA4 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA4)\n",
    "epochs = mne.Epochs(raw[5], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA5 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA5)\n",
    "epochs = mne.Epochs(raw[6], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA6 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA6)\n",
    "epochs = mne.Epochs(raw[7], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA7 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA7)\n",
    "epochs = mne.Epochs(raw[8], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA8 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA8)\n",
    "epochs = mne.Epochs(raw[9], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA9 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA9)\n",
    "epochs = mne.Epochs(raw[10], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA10 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA10)\n",
    "epochs = mne.Epochs(raw[11], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA11 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA11)\n",
    "epochs = mne.Epochs(raw[12], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA12 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA12)\n",
    "epochs = mne.Epochs(raw[13], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA13 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA13)\n",
    "epochs = mne.Epochs(raw[14], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA14 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA14)\n",
    "epochs = mne.Epochs(raw[15], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA15 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA15)\n",
    "epochs = mne.Epochs(raw[16], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA16 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA16)\n",
    "epochs = mne.Epochs(raw[17], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA17 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA17)\n",
    "epochs = mne.Epochs(raw[18], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA18 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA18)\n",
    "epochs = mne.Epochs(raw[19], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA19 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA19)\n",
    "epochs = mne.Epochs(raw[20], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA20 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA20)\n",
    "epochs = mne.Epochs(raw[21], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA21 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA21)\n",
    "epochs = mne.Epochs(raw[22], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA22 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA22)\n",
    "epochs = mne.Epochs(raw[23], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA23 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA23)\n",
    "epochs = mne.Epochs(raw[24], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA24 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA24)\n",
    "epochs = mne.Epochs(raw[25], events[0], event_id=[10], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA25 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA25)\n",
    "\n",
    "'''epochs = mne.Epochs(raw[26], events[0], new_event_id=[4], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classA26 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classA= np.append(classA,classA26)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fd9c75a-aca5-45eb-9851-dc6f2758da63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "25 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 25 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 80 events and 1876 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "epochs = mne.Epochs(raw[0], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "epochs = mne.Epochs(raw[1], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB1 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB1)\n",
    "epochs = mne.Epochs(raw[2], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB2 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB2)\n",
    "epochs = mne.Epochs(raw[3], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB3 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB3)\n",
    "epochs = mne.Epochs(raw[4], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB4 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB4)\n",
    "epochs = mne.Epochs(raw[5], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB5 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB5)\n",
    "epochs = mne.Epochs(raw[6], events[0], event_id=[1], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB6 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB6)\n",
    "epochs = mne.Epochs(raw[7], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB7 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB7)\n",
    "epochs = mne.Epochs(raw[8], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB8 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB8)\n",
    "epochs = mne.Epochs(raw[9], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB9 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB9)\n",
    "epochs = mne.Epochs(raw[10], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB10 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB10)\n",
    "epochs = mne.Epochs(raw[11], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB11 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB11)\n",
    "epochs = mne.Epochs(raw[12], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB12 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB12)\n",
    "epochs = mne.Epochs(raw[13], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB13 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB13)\n",
    "epochs = mne.Epochs(raw[14], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB14 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB14)\n",
    "epochs = mne.Epochs(raw[15], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB15 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB15)\n",
    "epochs = mne.Epochs(raw[16], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB16 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB16)\n",
    "epochs = mne.Epochs(raw[17], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB17 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB17)\n",
    "epochs = mne.Epochs(raw[18], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB18 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB18)\n",
    "epochs = mne.Epochs(raw[19], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB19 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB19)\n",
    "epochs = mne.Epochs(raw[20], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB20 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB20)\n",
    "epochs = mne.Epochs(raw[21], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB21 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB21)\n",
    "epochs = mne.Epochs(raw[22], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB22 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB22)\n",
    "epochs = mne.Epochs(raw[23], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB23 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB23)\n",
    "epochs = mne.Epochs(raw[24], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB24 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB24)\n",
    "epochs = mne.Epochs(raw[25], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "classB25 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "classB= np.append(classB,classB25)\n",
    "#epochs = mne.Epochs(raw[26], events[0], event_id=[11], tmin=0.0, tmax=7.5, baseline=(0, 0), preload=True)\n",
    "#classA26 = epochs.copy().crop(tmin=3.0, tmax=7.5).get_data()\n",
    "#classA= np.append(classA,classA26)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83344d04-b879-4492-989a-a15f19b93cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7026240,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7e6a284-3066-487f-9feb-400f6c9c2233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6840450,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45d0b7f4-ba8e-43d0-9dd2-c846679ba076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2080, 3, 1126)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the shape of the first class(left hand)\n",
    "newA=classA.reshape(2080,3,1126)\n",
    "newA.shape\n",
    "#type(newA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61523a03-43fa-4ef4-991a-fdfdb7824d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2025, 3, 1126)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newB=classB.reshape(2025,3,1126)\n",
    "#newA.shape\n",
    "newB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "092b1b92-ffb7-4b95-ada4-90379c1d96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as signal\n",
    "\n",
    "# Define the notch filter parameters\n",
    "fs = 250  # Sampling frequency\n",
    "notch_freq = 50.0  # Powerline frequency in Hz\n",
    "Q = 30.0  # Quality factor\n",
    "\n",
    "# Design a notch filter\n",
    "b, a = signal.iirnotch(notch_freq, Q, fs)\n",
    "\n",
    "# Apply the notch filter to EEG segments\n",
    "def apply_notch_filter(eeg_segments):\n",
    "    num_segments, num_channels, segment_length = eeg_segments.shape\n",
    "    filtered_segments = np.zeros_like(eeg_segments)\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        for j in range(num_channels):\n",
    "            filtered_segments[i, j] = signal.lfilter(b, a, eeg_segments[i, j])\n",
    "            \n",
    "    return filtered_segments\n",
    "\n",
    "filtered_class_A_segments = apply_notch_filter(newA)\n",
    "filtered_class_B_segments = apply_notch_filter(newB)\n",
    "\n",
    "# Now the EEG segments for both classes have the 50Hz powerline frequency removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9105428f-f459-430e-9e50-5c25413fe95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2080, 3, 1126)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_class_A_segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8272b1f-f9c9-4f56-ab94-0e84417278d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "2080 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>2080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>1: 2080</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>0.000 – 4.500 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>off</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<EpochsArray |  2080 events (all good), 0 - 4.5 sec, baseline off, ~53.6 MB, data loaded,\n",
       " '1': 2080>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the classA (first class details)\n",
    "A=[0]\n",
    "#A=mne.EpochsArray(filtered_class_A_segments,rawinfo)\n",
    "A=mne.EpochsArray(newA,rawinfo)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f73ad4c-48a1-446b-a600-fba571260bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "2025 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>1: 2025</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>0.000 – 4.500 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>off</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<EpochsArray |  2025 events (all good), 0 - 4.5 sec, baseline off, ~52.2 MB, data loaded,\n",
       " '1': 2025>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=[0]\n",
    "#B=mne.EpochsArray(filtered_class_B_segments,rawinfo)\n",
    "B=mne.EpochsArray(newB,rawinfo)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "baf5ee24-eb7c-4add-9a0b-412998a82409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the bandpass filter function\n",
    "def butter_bandpass_filter(signal, lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut/nyq\n",
    "    high = highcut/nyq\n",
    "    b,a = butter(order, [low, high], btype='band')\n",
    "    y = lfilter(b, a, signal, axis=-1)  \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29f8ff07-4dc8-4bda-90ed-9f61ab4d5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delta bandpass filter from class A\n",
    "def read_da(path):\n",
    "    fs = 250\n",
    "    lowcut = 0.5\n",
    "    highcut = 3.99\n",
    "    delta= butter_bandpass_filter(A, lowcut, highcut, fs, order=5)\n",
    "    mean_filtered_data = np.mean(delta, axis=-1)\n",
    "    return mean_filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "940018f4-9e74-407e-ae1b-d4374179d15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2080, 3)\n"
     ]
    }
   ],
   "source": [
    "#getting the shape of the delta for classA\n",
    "deltaA=[0]\n",
    "deltaA=read_da(A)\n",
    "print(deltaA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed3af64c-b5cf-43db-845f-1ddc266be5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delta bandpass filter from class B\n",
    "def read_db(path):\n",
    "    fs = 250\n",
    "    lowcut = 0.5\n",
    "    highcut = 3.99\n",
    "    delta= butter_bandpass_filter(B, lowcut, highcut, fs, order=5)\n",
    "    delta = np.mean(delta, axis=-1)\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d4cbf2e-127f-4833-acf7-0341f4b29355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2025, 3)\n"
     ]
    }
   ],
   "source": [
    "#getting the shape of the delta for classB\n",
    "deltaB=[0] \n",
    "deltaB=read_db(B)\n",
    "print(deltaB.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf1518b7-79d2-4ff0-bb88-e72e2484d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#theta bandpass filter from class A\n",
    "def read_de(path):\n",
    "    fs = 250\n",
    "    lowcut = 4\n",
    "    highcut = 7.99\n",
    "    theta= butter_bandpass_filter(A, lowcut, highcut, fs, order=5)\n",
    "    theta = np.mean(theta, axis=-1)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dffd243-b517-4e7d-abd2-592dee33a59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2080, 3)\n"
     ]
    }
   ],
   "source": [
    "#getting the shape of the theta for class A\n",
    "thetaA=[0]\n",
    "thetaA=read_de(A)\n",
    "print(thetaA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "917d45b2-0a82-469c-be59-6e5e083792cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Theta bandpass filter from class B\n",
    "def read_df(path):\n",
    "    fs = 250\n",
    "    lowcut = 4\n",
    "    highcut = 7.99\n",
    "    theta= butter_bandpass_filter(B, lowcut, highcut, fs, order=5)\n",
    "    theta = np.mean(theta, axis=-1)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a9f5f0f-b968-4ce7-adb4-0350628f8e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2025, 3)\n"
     ]
    }
   ],
   "source": [
    "#getting the shape of the theta for class B\n",
    "thetaB=[0]\n",
    "thetaB=read_df(B)\n",
    "print(thetaB.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4323dd95-453e-4be2-8a9c-0da4cc67f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alpha bandpass filter from class A\n",
    "def read_di(path):\n",
    "    fs = 250\n",
    "    lowcut = 8.01\n",
    "    highcut = 11.99\n",
    "    alpha= butter_bandpass_filter(A, lowcut, highcut, fs, order=5)\n",
    "    alpha = np.mean(alpha, axis=-1)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65611c47-216a-45fa-ae76-0b4720f56ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2080, 3)\n"
     ]
    }
   ],
   "source": [
    "#getting the shape of the alpha for class A\n",
    "alphaA=[0]\n",
    "alphaA=read_di(A)\n",
    "print(alphaA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd1230a1-175c-413c-b74f-9fe18c412e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alpha bandpass filter from class B\n",
    "def read_dj(path):\n",
    "    fs = 250\n",
    "    lowcut = 8.01\n",
    "    highcut = 11.99\n",
    "    alpha= butter_bandpass_filter(B, lowcut, highcut, fs, order=5)\n",
    "    alpha = np.mean(alpha, axis=-1)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12834068-319b-4ef4-82d5-6ea1bdb78a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2025, 3)\n"
     ]
    }
   ],
   "source": [
    "#getting the shape of the alpha of class B\n",
    "alphaB=[0]\n",
    "alphaB=read_dj(B)\n",
    "print(alphaB.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1838c07-79be-404f-9de5-87c102da2723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beta bandpass filter from class A\n",
    "def read_dm(path):\n",
    "    fs = 250\n",
    "    lowcut = 12.01\n",
    "    highcut = 29.99\n",
    "    beta= butter_bandpass_filter(A, lowcut, highcut, fs, order=5)\n",
    "    beta = np.mean(beta, axis=-1)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45fe0dfa-e87b-4d24-adff-b462fa237a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2080, 3)\n"
     ]
    }
   ],
   "source": [
    "#getting the shape of the beta of class A\n",
    "betaA=[0]\n",
    "betaA=read_dm(A)\n",
    "print(betaA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5dd6e45-c6f0-429f-9dce-40a99dabba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beta bandpass filter from class B\n",
    "def read_dn(path):\n",
    "    fs = 250\n",
    "    lowcut = 12.01\n",
    "    highcut = 29.99\n",
    "    beta= butter_bandpass_filter(B, lowcut, highcut, fs, order=5)\n",
    "    beta = np.mean(beta, axis=-1)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd783b21-76a4-40da-a6dc-dcf813609772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2025, 3)\n"
     ]
    }
   ],
   "source": [
    "#getting the shape of the beta of class B\n",
    "betaB=[0]\n",
    "betaB=read_dn(B)\n",
    "print(betaB.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1cabf3b3-42e2-4104-9602-4f44c9792dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gamma bandpass filter from class A\n",
    "def read_dq(path):\n",
    "    fs = 250\n",
    "    lowcut = 30.01\n",
    "    highcut = 100\n",
    "    gamma= butter_bandpass_filter(A, lowcut, highcut, fs, order=5)\n",
    "    gamma = np.mean(gamma, axis=-1)\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "948fd139-4af6-4975-abe6-a31ab8dbd564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2080, 3)\n"
     ]
    }
   ],
   "source": [
    "#getting the shape of the gamma of class A\n",
    "gammaA=[0]\n",
    "gammaA=read_dq(A)\n",
    "print(gammaA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90769fe9-e91f-4f00-8927-eda7a00fa24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gamma bandpass filter from class B\n",
    "def read_dr(path):\n",
    "    fs = 250\n",
    "    lowcut = 30.01\n",
    "    highcut = 100\n",
    "    gamma= butter_bandpass_filter(B, lowcut, highcut, fs, order=5)\n",
    "    gamma = np.mean(gamma, axis=-1)\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60a359b3-9a93-48a6-bfdf-90892a9040e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2025, 3)\n"
     ]
    }
   ],
   "source": [
    "#getting the shape of the gamma of class B\n",
    "gammaB=[0]\n",
    "gammaB=read_dr(B)\n",
    "print(gammaB.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7828805d-931e-42bb-ade8-3699f48b40b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_median_features(eeg_signals):\n",
    "    mean_median_features = []\n",
    "\n",
    "    for signal in eeg_signals:\n",
    "        segment_features = []\n",
    "\n",
    "        for segment in signal:\n",
    "            mean_feat = np.mean(segment)\n",
    "            median_feat = np.median(segment)\n",
    "            \n",
    "            segment_features.append(mean_feat)\n",
    "            segment_features.append(median_feat)\n",
    "        \n",
    "        mean_median_features.append(segment_features)\n",
    "\n",
    "    return np.array(mean_median_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8eb629bc-a362-40b6-ae0f-436d7a344f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2080, 6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanmedianA=calculate_mean_median_features(A)\n",
    "meanmedianA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a26368b6-5604-4320-9251-8643458ca20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2025, 6)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanmedianB=calculate_mean_median_features(B)\n",
    "meanmedianB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5d7a74c-f4de-40f5-af24-cceccca59379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Hjorth parameters for each EEG segment\n",
    "def hjorth_parameters(eeg_segment):\n",
    "    activity = np.var(eeg_segment)\n",
    "    diff_signal = np.diff(eeg_segment)\n",
    "    mobility = np.var(diff_signal)\n",
    "    diff2_signal = np.diff(diff_signal)\n",
    "    complexity = np.var(diff2_signal)\n",
    "    \n",
    "    return activity, mobility, complexity\n",
    "\n",
    "# Calculate Hjorth features for all segments in the EEG signals\n",
    "def calculate_hjorth_features(eeg_signals):\n",
    "    hjorth_features = []\n",
    "\n",
    "    for signal in eeg_signals:\n",
    "        segment_features = []\n",
    "\n",
    "        for segment in signal:\n",
    "            hjorth_feats = hjorth_parameters(segment)\n",
    "            segment_features.extend(hjorth_feats)\n",
    "        \n",
    "        hjorth_features.append(segment_features)\n",
    "\n",
    "    return np.array(hjorth_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b9e9165-9496-4116-ac28-66d266c2054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hjorth_features_class_A = calculate_hjorth_features(A)\n",
    "hjorth_features_class_B = calculate_hjorth_features(B)\n",
    "\n",
    "# Create labels for class A and class B\n",
    "labels_class_A = np.zeros(len(hjorth_features_class_A))  \n",
    "labels_class_B = np.ones(len(hjorth_features_class_B))   \n",
    "\n",
    "# Concatenate the Hjorth features and labels for both classes\n",
    "all_hjorth_features = np.concatenate((hjorth_features_class_A, hjorth_features_class_B), axis=0)\n",
    "all_labels = np.concatenate((labels_class_A, labels_class_B))\n",
    "#all_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8cea0c6a-4d20-4522-ae75-2a42a56e5063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannon_entropy(signal):\n",
    "    # Compute the histogram of the signal\n",
    "    hist, _ = np.histogram(signal, bins=256, range=(0, 256))\n",
    "    \n",
    "    # Normalize the histogram\n",
    "    hist = hist / (len(signal) * 1.0)\n",
    "    \n",
    "    # Calculate Shannon entropy\n",
    "    entropy = -np.sum([p * np.log2(p + np.finfo(float).eps) for p in hist if p > 0])\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def calculate_shannon_entropy_features(eeg_signals):\n",
    "    shannon_entropy_features = []\n",
    "\n",
    "    for signal in eeg_signals:\n",
    "        segment_features = []\n",
    "\n",
    "        for segment in signal:\n",
    "            entropy_feat = shannon_entropy(segment)\n",
    "            segment_features.append(entropy_feat)\n",
    "        \n",
    "        shannon_entropy_features.append(segment_features)\n",
    "\n",
    "    return np.array(shannon_entropy_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce59fac4-16d8-4ff3-b6a4-b8564e456c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install PyWavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f21d954c-74c2-4a20-aac4-e97e40c9d703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2080, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shanon_A=calculate_shannon_entropy_features(A)\n",
    "shanon_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e984ed6a-47b9-4e97-bb30-b97f487ede1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2025, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shanon_B=calculate_shannon_entropy_features(B)\n",
    "shanon_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d94793d-777a-4edf-b08c-6b3c5cfe1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "def calculate_wavelet_features(eeg_signals, wavelet='db4', level=4):\n",
    "    wavelet_features = []\n",
    "\n",
    "    for signal in eeg_signals:\n",
    "        segment_features = []\n",
    "\n",
    "        for segment in signal:\n",
    "            # Apply discrete wavelet transform\n",
    "            coeffs = pywt.wavedec(segment, wavelet, level=level)\n",
    "            \n",
    "            # Extract the approximation and detail coefficients\n",
    "            approx = coeffs[0]\n",
    "            details = np.concatenate(coeffs[1:])\n",
    "            \n",
    "            # Calculate statistical features (mean, variance, etc.) on coefficients\n",
    "            mean = np.mean(details)\n",
    "            variance = np.var(details)\n",
    "            energy = np.sum(np.square(details))\n",
    "            \n",
    "            # Append wavelet features for this segment\n",
    "            segment_features.extend([mean, variance, energy])\n",
    "        \n",
    "        wavelet_features.append(segment_features)\n",
    "\n",
    "    return np.array(wavelet_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5fcea52f-481b-4d0d-814e-968736b03373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2080, 9)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Assuming eeg_signals is a list of EEG signal segments, where each segment is a 1D numpy array.\n",
    "wavelet_features_A = calculate_wavelet_features(A)\n",
    "wavelet_features_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "176eebdc-1bf5-48e6-9a27-f4c8051d1bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2025, 9)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavelet_features_B = calculate_wavelet_features(B)\n",
    "wavelet_features_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53ca05d4-7690-453d-9761-ff74ff612d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53e481a9-4d44-4360-b959-8eaf0c04185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def calculate_skewness_kurtosis_features(eeg_signals):\n",
    "    skewness_features = []\n",
    "    kurtosis_features = []\n",
    "\n",
    "    for signal in eeg_signals:\n",
    "        segment_skewness = []\n",
    "        segment_kurtosis = []\n",
    "\n",
    "        for segment in signal:\n",
    "            # Calculate skewness and kurtosis for each segment\n",
    "            skew_val = skew(segment)\n",
    "            kurtosis_val = kurtosis(segment)\n",
    "\n",
    "            segment_skewness.append(skew_val)\n",
    "            segment_kurtosis.append(kurtosis_val)\n",
    "\n",
    "        # Append skewness and kurtosis features for this signal\n",
    "        skewness_features.append(segment_skewness)\n",
    "        kurtosis_features.append(segment_kurtosis)\n",
    "\n",
    "    return np.array(skewness_features), np.array(kurtosis_features)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming eeg_signals is a list of EEG signal segments, where each segment is a 1D numpy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31bec15e-7577-4984-af5f-fdede7a24dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2080, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewness_A, kurtosis_A = calculate_skewness_kurtosis_features(A)\n",
    "skewness_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47410005-0c18-4f72-ae95-cb73c3901871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2080, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kurtosis_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9a1105ad-35f1-4294-99bf-0208b521edf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2025, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewness_B, kurtosis_B = calculate_skewness_kurtosis_features(B)\n",
    "skewness_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "62b8c7b6-1bae-4ea8-852b-e359a03575e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2025, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kurtosis_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6f930549-b845-4513-8002-c7f041fb4afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12315,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aDelta=np.append(deltaA,deltaB)\n",
    "aDelta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "41714546-afd4-4322-9261-3c12239ba055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4105, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltaAll=aDelta.reshape(4105,3)\n",
    "deltaAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "691a1fea-576f-4e83-8925-471929ee5fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12315,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aTheta=np.append(thetaA,thetaB)\n",
    "aTheta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b598ea5a-fb2a-4e2a-b0ac-6cf8bfc4a7f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4105, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetaAll=aTheta.reshape(4105,3)\n",
    "thetaAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7a70d76-b82d-4008-be1b-1a7624378c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12315,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aAlpha=np.append(alphaA,alphaB)\n",
    "aAlpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1930e9e8-b443-429e-ac1e-0f55da37da48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4105, 3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphaAll=aAlpha.reshape(4105,3)\n",
    "alphaAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6fe69616-43eb-40ed-a5e4-aa1761d5f600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12315,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aBeta=np.append(betaA,betaB)\n",
    "aBeta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "22d6e600-929a-431d-b650-ccddbd67a275",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4105, 3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betaAll=aBeta.reshape(4105,3)\n",
    "betaAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "34a51cf6-4d1d-4b17-8d59-07b050b81000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12315,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aGamma=np.append(gammaA,gammaB)\n",
    "aGamma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8bc6e57a-e5c7-42ef-a2a9-a577e94ca3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4105, 3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gammaAll=aGamma.reshape(4105,3)\n",
    "gammaAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c0eaa54c-fc33-48f4-a435-26992cbac949",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36945,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hjorthAll=np.append(hjorth_features_class_A,hjorth_features_class_B)\n",
    "hjorthAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "248a5476-61bd-4ba3-9566-c3f0d610aa99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4105, 9)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hjorthAll=hjorthAll.reshape(4105,9)\n",
    "hjorthAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8b28f6ec-efed-453b-b59f-e40d4e5b6a55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24630,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanmedianAll=np.append(meanmedianA,meanmedianB)\n",
    "meanmedianAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ea39ffc2-4e39-46c2-af1b-82a820314aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4105, 6)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanmedianAll=meanmedianAll.reshape(4105,6)\n",
    "meanmedianAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d99f4e40-2f2f-4c23-8dfe-2c7ec995505e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12315,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shanonAll=np.append(shanon_A,shanon_B)\n",
    "shanonAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cdb6a140-b5d8-49d3-ad4b-218d38e38367",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4105, 3)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shanonAll=shanonAll.reshape(4105,3)\n",
    "shanonAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "815e7a59-5b04-4111-b46d-38e58f0e2500",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36945,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavelet_featuresAll=np.append(wavelet_features_A,wavelet_features_B)\n",
    "wavelet_featuresAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6d44cc49-287f-4275-8139-d805e28e22d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4105, 9)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavelet_featuresAll=wavelet_featuresAll.reshape(4105,9)\n",
    "wavelet_featuresAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b0ac7e56-3730-4f45-9864-f8bcfb4cf146",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12315,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewnessAll=np.append(skewness_A,skewness_B)\n",
    "skewnessAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6b561c3d-d2a6-46e9-b10c-522c1053a550",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4105, 3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewnessAll=skewnessAll.reshape(4105,3)\n",
    "skewnessAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cbfbd17e-553f-45a3-b3a8-a61868b6f088",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12315,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kurtosisAll=np.append(kurtosis_A,kurtosis_B)\n",
    "kurtosisAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b9895e6f-eaa0-412e-bbd1-c3df90987cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4105, 3)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kurtosisAll=kurtosisAll.reshape(4105,3)\n",
    "kurtosisAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e6ef5b7a-d748-4cb3-9cc8-dc220dd73881",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4105, 48)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otherData=np.column_stack((deltaAll,thetaAll,alphaAll,betaAll,gammaAll,hjorthAll,meanmedianAll,shanonAll,wavelet_featuresAll,skewnessAll, kurtosisAll))\n",
    "otherData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8c8b0ba8-3a6e-49df-8cf0-e8354c3495ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xpother=np.empty(4105,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "40399d23-ac36-438e-8294-b3a90c8bc7d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4105,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,2080):\n",
    "    xpother[i]=0\n",
    "for i in range(2080,4105):\n",
    "    xpother[i]=1\n",
    "xpother.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9214afa5-f39f-49d3-bb5b-fb29c8aa500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(otherData,xpother,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d201d83-5fd5-47c7-ad09-ed294c9b2576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ac=StandardScaler()\n",
    "x_train=ac.fit_transform(x_train)\n",
    "x_test=ac.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8d6bfcc5-105b-4111-9f24-58d0bf98cb87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "classknn=KNeighborsClassifier(n_neighbors=10,metric='minkowski',p=2)\n",
    "classknn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dfb38682-21d4-4659-ba77-e3313a65a54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred=classknn.predict(x_test)\n",
    "y_pred.shape\n",
    "#y_pred=classifier.predict(y_test_n)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5ec7ca0d-80b2-4ceb-94ae-3ae7ed43db65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[249 161]\n",
      " [253 158]]\n",
      "0.49573690621193667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm= confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "775c85db-b62d-43d2-a3d1-b48e97cbaa9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Feature selected : 2\n",
      "[[210 200]\n",
      " [216 195]]\n",
      "0.4933008526187576\n",
      "No of Feature selected : 3\n",
      "[[213 197]\n",
      " [208 203]]\n",
      "0.5066991473812423\n",
      "No of Feature selected : 4\n",
      "[[235 175]\n",
      " [189 222]]\n",
      "0.5566382460414129\n",
      "No of Feature selected : 5\n",
      "[[224 186]\n",
      " [210 201]]\n",
      "0.5176613885505481\n",
      "No of Feature selected : 6\n",
      "[[223 187]\n",
      " [217 194]]\n",
      "0.5079171741778319\n",
      "No of Feature selected : 7\n",
      "[[223 187]\n",
      " [217 194]]\n",
      "0.5079171741778319\n",
      "No of Feature selected : 8\n",
      "[[213 197]\n",
      " [199 212]]\n",
      "0.5176613885505481\n",
      "No of Feature selected : 9\n",
      "[[218 192]\n",
      " [200 211]]\n",
      "0.5225334957369062\n",
      "No of Feature selected : 10\n",
      "[[211 199]\n",
      " [195 216]]\n",
      "0.5200974421437271\n",
      "No of Feature selected : 11\n",
      "[[215 195]\n",
      " [198 213]]\n",
      "0.5213154689403167\n",
      "No of Feature selected : 12\n",
      "[[208 202]\n",
      " [208 203]]\n",
      "0.5006090133982948\n",
      "No of Feature selected : 13\n",
      "[[203 207]\n",
      " [196 215]]\n",
      "0.5091352009744214\n",
      "No of Feature selected : 14\n",
      "[[207 203]\n",
      " [201 210]]\n",
      "0.5079171741778319\n",
      "No of Feature selected : 15\n",
      "[[208 202]\n",
      " [193 218]]\n",
      "0.5188794153471377\n",
      "No of Feature selected : 16\n",
      "[[209 201]\n",
      " [201 210]]\n",
      "0.510353227771011\n",
      "No of Feature selected : 17\n",
      "[[206 204]\n",
      " [193 218]]\n",
      "0.5164433617539586\n",
      "No of Feature selected : 18\n",
      "[[208 202]\n",
      " [202 209]]\n",
      "0.5079171741778319\n",
      "No of Feature selected : 19\n",
      "[[204 206]\n",
      " [204 207]]\n",
      "0.5006090133982948\n",
      "No of Feature selected : 20\n",
      "[[203 207]\n",
      " [203 208]]\n",
      "0.5006090133982948\n",
      "No of Feature selected : 21\n",
      "[[219 191]\n",
      " [193 218]]\n",
      "0.5322777101096224\n",
      "No of Feature selected : 22\n",
      "[[217 193]\n",
      " [194 217]]\n",
      "0.5286236297198539\n",
      "No of Feature selected : 23\n",
      "[[221 189]\n",
      " [195 216]]\n",
      "0.5322777101096224\n",
      "No of Feature selected : 24\n",
      "[[215 195]\n",
      " [195 216]]\n",
      "0.5249695493300852\n",
      "No of Feature selected : 25\n",
      "[[209 201]\n",
      " [190 221]]\n",
      "0.5237515225334958\n",
      "No of Feature selected : 26\n",
      "[[206 204]\n",
      " [188 223]]\n",
      "0.5225334957369062\n",
      "No of Feature selected : 27\n",
      "[[204 206]\n",
      " [201 210]]\n",
      "0.5042630937880633\n",
      "No of Feature selected : 28\n",
      "[[203 207]\n",
      " [203 208]]\n",
      "0.5006090133982948\n",
      "No of Feature selected : 29\n",
      "[[197 213]\n",
      " [207 204]]\n",
      "0.4884287454323995\n",
      "No of Feature selected : 30\n",
      "[[203 207]\n",
      " [202 209]]\n",
      "0.5018270401948843\n",
      "No of Feature selected : 31\n",
      "[[184 226]\n",
      " [194 217]]\n",
      "0.4884287454323995\n",
      "No of Feature selected : 32\n",
      "[[194 216]\n",
      " [210 201]]\n",
      "0.48112058465286234\n",
      "No of Feature selected : 33\n",
      "[[189 221]\n",
      " [208 203]]\n",
      "0.4774665042630938\n",
      "No of Feature selected : 34\n",
      "[[193 217]\n",
      " [207 204]]\n",
      "0.4835566382460414\n",
      "No of Feature selected : 35\n",
      "[[198 212]\n",
      " [209 202]]\n",
      "0.48721071863581\n",
      "No of Feature selected : 36\n",
      "[[215 195]\n",
      " [192 219]]\n",
      "0.5286236297198539\n",
      "No of Feature selected : 37\n",
      "[[215 195]\n",
      " [196 215]]\n",
      "0.5237515225334958\n",
      "No of Feature selected : 38\n",
      "[[211 199]\n",
      " [196 215]]\n",
      "0.5188794153471377\n",
      "No of Feature selected : 39\n",
      "[[192 218]\n",
      " [212 199]]\n",
      "0.4762484774665043\n",
      "No of Feature selected : 40\n",
      "[[189 221]\n",
      " [209 202]]\n",
      "0.4762484774665043\n",
      "No of Feature selected : 41\n",
      "[[186 224]\n",
      " [208 203]]\n",
      "0.47381242387332523\n",
      "No of Feature selected : 42\n",
      "[[185 225]\n",
      " [212 199]]\n",
      "0.46772228989037756\n",
      "No of Feature selected : 43\n",
      "[[186 224]\n",
      " [211 200]]\n",
      "0.4701583434835566\n",
      "No of Feature selected : 44\n",
      "[[191 219]\n",
      " [208 203]]\n",
      "0.47990255785627284\n",
      "No of Feature selected : 45\n",
      "[[193 217]\n",
      " [204 207]]\n",
      "0.48721071863581\n",
      "No of Feature selected : 46\n",
      "[[204 206]\n",
      " [209 202]]\n",
      "0.4945188794153471\n",
      "No of Feature selected : 47\n",
      "[[209 201]\n",
      " [213 198]]\n",
      "0.49573690621193667\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "mic_scores = []\n",
    "selected_features=[]\n",
    "def calculate_MIC(x, y):\n",
    "    # Calculate Pearson correlation coefficient (r) between x and y\n",
    "    r, _ = pearsonr(x, y)\n",
    "    \n",
    "    # Calculate MIC using the formula MIC = |r| * log2(n)\n",
    "    n = len(x)\n",
    "    mic = abs(r) * np.log2(n)\n",
    "    \n",
    "    return mic\n",
    "\n",
    "for i in range(0,48):\n",
    "    #mine.compute_score(x_train[:, feature_idx], y_train)\n",
    "    mic_score = calculate_MIC(otherData[:, i], xpother)\n",
    "    mic_scores.append(mic_score)\n",
    "\n",
    "\n",
    "# Sort features based on MIC scores (in descending order)\n",
    "sorted_features = np.argsort(mic_scores)[::-1]\n",
    "\n",
    "# Select the top 20 features\n",
    "for i in range(2,48):\n",
    "    top_20_features = sorted_features[:i]\n",
    "    top_20_feature_values = otherData[:, top_20_features]\n",
    "    \n",
    "    x_train,x_test,y_train,y_test=train_test_split(top_20_feature_values,xpother,test_size=0.2,random_state=0)\n",
    "   \n",
    "    ac=StandardScaler()\n",
    "    x_train=ac.fit_transform(x_train)\n",
    "    x_test=ac.transform(x_test)\n",
    "    \n",
    "    classknn=KNeighborsClassifier(n_neighbors=9,metric='minkowski',p=2)\n",
    "    classknn.fit(x_train,y_train)\n",
    "    y_pred=classknn.predict(x_test)\n",
    "    cm= confusion_matrix(y_test, y_pred)\n",
    "    print(\"No of Feature selected :\",i)\n",
    "    print(cm)\n",
    "    print(accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cc164057-df12-449b-a56b-bcc4c960502c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Feature selected :4\n",
      "[[235 175]\n",
      " [189 222]]\n",
      "0.5566382460414129\n"
     ]
    }
   ],
   "source": [
    "#Highest accuracy gained after feature selection using knn\n",
    "top_20_features = sorted_features[:4]\n",
    "top_20_feature_values = otherData[:, top_20_features]\n",
    "#train-test\n",
    "x_train,x_test,y_train,y_test=train_test_split(top_20_feature_values,xpother,test_size=0.2,random_state=0)\n",
    "#feature-scaling\n",
    "ac=StandardScaler()\n",
    "x_train=ac.fit_transform(x_train)\n",
    "x_test=ac.transform(x_test)\n",
    "#classification\n",
    "classknn=KNeighborsClassifier(n_neighbors=9,metric='minkowski',p=2)\n",
    "classknn.fit(x_train,y_train)\n",
    "#prediction\n",
    "y_pred=classknn.predict(x_test)\n",
    "#confusion matrix\n",
    "cm= confusion_matrix(y_test, y_pred)\n",
    "print(\"No of Feature selected :4\")\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
