{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "410a28c9-eec7-4704-ad62-c726258e548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing modules\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as df\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.signal import freqz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76467d92-8c78-4b9a-a108-90f2e83127ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\DEBMALYA\\OneDrive\\Desktop\\Work\\A01T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEBMALYA\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n",
      "Extracting EDF parameters from C:\\Users\\DEBMALYA\\OneDrive\\Desktop\\Work\\A02T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 677168  =      0.000 ...  2708.672 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEBMALYA\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\DEBMALYA\\OneDrive\\Desktop\\Work\\A03T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 660529  =      0.000 ...  2642.116 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEBMALYA\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\DEBMALYA\\OneDrive\\Desktop\\Work\\A05T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 686119  =      0.000 ...  2744.476 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEBMALYA\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\DEBMALYA\\OneDrive\\Desktop\\Work\\A06T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 678979  =      0.000 ...  2715.916 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEBMALYA\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\DEBMALYA\\OneDrive\\Desktop\\Work\\A07T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 681070  =      0.000 ...  2724.280 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEBMALYA\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\DEBMALYA\\OneDrive\\Desktop\\Work\\A08T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 675269  =      0.000 ...  2701.076 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEBMALYA\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\DEBMALYA\\OneDrive\\Desktop\\Work\\A09T.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 673327  =      0.000 ...  2693.308 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEBMALYA\\anaconda3\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    }
   ],
   "source": [
    "#dropping the eog channels working only on 22 eeg channels of 9 files\n",
    "file_paths_1 = [\n",
    "    'A01T.gdf',\n",
    "    'A02T.gdf',\n",
    "    'A03T.gdf',\n",
    "    \n",
    "    'A05T.gdf',\n",
    "    'A06T.gdf',\n",
    "    'A07T.gdf',\n",
    "    'A08T.gdf',\n",
    "    'A09T.gdf'\n",
    "]\n",
    "raw = []\n",
    "\n",
    "for file_path in file_paths_1:\n",
    "    raw_data = mne.io.read_raw_gdf(file_path,preload=True, eog=['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "    \n",
    "    p=raw_data.drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "    raw.append(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b37b113-1d8f-4087-b9b1-90736c2835a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n"
     ]
    }
   ],
   "source": [
    "#Annotation object for annotating segments of raw data.\n",
    "for i in range(0,8):\n",
    "    raw[i].annotations\n",
    "    events=mne.events_from_annotations(raw[i])\n",
    "    #printing the 1st index of the events which contains the overall details of the file\n",
    "    events[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe7ade9-f35f-4c9f-95ea-36aa5038b13d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#getting the rawinfo(information of each file)\n",
    "rawinfo=[]\n",
    "for i in range(0,8):\n",
    "    rawinfo=np.append(rawinfo,raw[i].info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c0758a7-348d-4538-b12e-7480946b1963",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EEG-Fz',\n",
       " 'EEG-0',\n",
       " 'EEG-1',\n",
       " 'EEG-2',\n",
       " 'EEG-3',\n",
       " 'EEG-4',\n",
       " 'EEG-5',\n",
       " 'EEG-C3',\n",
       " 'EEG-6',\n",
       " 'EEG-Cz',\n",
       " 'EEG-7',\n",
       " 'EEG-C4',\n",
       " 'EEG-8',\n",
       " 'EEG-9',\n",
       " 'EEG-10',\n",
       " 'EEG-11',\n",
       " 'EEG-12',\n",
       " 'EEG-13',\n",
       " 'EEG-14',\n",
       " 'EEG-Pz',\n",
       " 'EEG-15',\n",
       " 'EEG-16']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawinfo[0].ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c664c320-158c-413d-a588-185feb9a81a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a event dictionary\n",
    "event_dict={\n",
    " 'reject':1,\n",
    " 'eye move':2,\n",
    " 'eye open':3,\n",
    " 'eye close':4,\n",
    " 'new run':5,\n",
    " 'new trial':6,\n",
    " 'class 1':7,\n",
    " 'class 2':8,\n",
    " 'class 3':9,\n",
    " 'class 4':10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77c573c8-2f22-4ca6-bbcc-b90c36a7c0f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "72 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 72 events and 1476 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 72 events and 1476 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 72 events and 1476 original time points ...\n",
      "1 bad epochs dropped\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 72 events and 1476 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 72 events and 1476 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 72 events and 1476 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 72 events and 1476 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 72 events and 1476 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "#taking classA of 9 subjects\n",
    "classA=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    epochs = mne.Epochs(raw[i], events[0], event_id=[7], tmin=0.0, tmax=5.9, baseline=(0, 0), preload=True)\n",
    "    classA[i] = epochs.copy().crop(tmin=2.0, tmax=5.9).get_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0467759b-ef6f-4692-8a05-d653b402dce3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "72 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 72 events and 1476 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 72 events and 1476 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 72 events and 1476 original time points ...\n",
      "2 bad epochs dropped\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 72 events and 1476 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 72 events and 1476 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 72 events and 1476 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 72 events and 1476 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 72 events and 1476 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "#taking classB of 9 subjects\n",
    "classB=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    epochs = mne.Epochs(raw[i], events[0], event_id=[8], tmin=0.0, tmax=5.9, baseline=(0, 0), preload=True)\n",
    "    classB[i] = epochs.copy().crop(tmin=2.0, tmax=5.9).get_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65683c2f-664e-43da-a9e4-3257334f1a63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 22, 976)\n",
      "(72, 22, 976)\n",
      "(70, 22, 976)\n",
      "(72, 22, 976)\n",
      "(72, 22, 976)\n",
      "(72, 22, 976)\n",
      "(72, 22, 976)\n",
      "(72, 22, 976)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,8):\n",
    "    print(classB[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27f864e6-6a5e-4879-9794-1155625a4483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "72 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "71 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "#converting the classA to epochsArray\n",
    "A=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    A[i]=mne.EpochsArray(classA[i],rawinfo[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db60a74f-4d28-4c01-be00-023b654da29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "72 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "70 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "#converting the classB to epochsArray\n",
    "B=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    B[i]=mne.EpochsArray(classB[i],rawinfo[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39fcf5bb-c644-4a58-81d2-67a0575061e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0,8):\n",
    "    min_val = np.min(A[i], axis=2, keepdims=True)\n",
    "    max_val = np.max(A[i], axis=2, keepdims=True)\n",
    "    A[i] = (A[i] - min_val) / (max_val - min_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aec52d9b-cc19-40a5-a888-a9a6b3640e96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0,3):\n",
    "    min_val = np.min(B[i], axis=2, keepdims=True)\n",
    "    max_val = np.max(B[i], axis=2, keepdims=True)\n",
    "    B[i] = (B[i] - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc6f98e1-ab75-4a07-9bd4-b9c43b73976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the bandpass filter function\n",
    "def butter_bandpass_filter(signal, lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut/nyq\n",
    "    high = highcut/nyq\n",
    "    b,a = butter(order, [low, high], btype='band')\n",
    "    y = lfilter(b, a, signal, axis=-1)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9b79dc5-e69b-494b-bc53-99136dae6dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delta bandpass filter from class A\n",
    "def read_da(i):\n",
    "    fs = 250\n",
    "    lowcut = 0.5\n",
    "    highcut = 3.99\n",
    "    delta= butter_bandpass_filter(A[i], lowcut, highcut, fs, order=5)\n",
    "    delta = np.mean(delta, axis=-1)\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6da4e29f-7034-4b4f-bb56-4ecb0058d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function for delta of classA separately for each files\n",
    "deltaA=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    deltaA[i]=read_da(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4315aa22-d3d4-4b2b-b34e-743d6a69b33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delta bandpass filter from class B\n",
    "def read_db(i):\n",
    "    fs = 250\n",
    "    lowcut = 0.5\n",
    "    highcut = 3.99\n",
    "    delta= butter_bandpass_filter(B[i], lowcut, highcut, fs, order=5)\n",
    "    delta = np.mean(delta, axis=-1)\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84125aba-e8b2-4164-af42-3890cba02435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function for delta of classB separately for each files\n",
    "deltaB=[0,0,0,0,0,0,0,0] \n",
    "for i in range(0,8):\n",
    "    deltaB[i]=read_db(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f529ec02-f9f9-4183-9a6d-6bf8161592e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#theta bandpass filter from class A\n",
    "def read_de(i):\n",
    "    fs = 250\n",
    "    lowcut = 4\n",
    "    highcut = 7.99\n",
    "    theta= butter_bandpass_filter(A[i], lowcut, highcut, fs, order=5)\n",
    "    theta = np.mean(theta, axis=-1)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd7e4278-89a3-417e-9ca3-50c68359dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function for theta of classA separately for each files\n",
    "thetaA=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    thetaA[i]=read_de(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d59c1dd3-d75a-444e-9812-1b899c3ea913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Theta bandpass filter from class B\n",
    "def read_df(i):\n",
    "    fs = 250\n",
    "    lowcut = 4\n",
    "    highcut = 7.99\n",
    "    theta= butter_bandpass_filter(B[i], lowcut, highcut, fs, order=5)\n",
    "    theta = np.mean(theta, axis=-1)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99adf8c1-2a32-4a78-a5ff-042719c66059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function for theta of classB separately for each files\n",
    "thetaB=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    thetaB[i]=read_df(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7750c171-9dd3-4591-85ff-89f164b91194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alpha bandpass filter from class A\n",
    "def read_di(i):\n",
    "    fs = 250\n",
    "    lowcut = 8.01\n",
    "    highcut = 11.99\n",
    "    alpha= butter_bandpass_filter(A[i], lowcut, highcut, fs, order=5)\n",
    "    alpha = np.mean(alpha, axis=-1)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab12c7e8-4f47-4220-a531-d71b5f234b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function for alpha of classA separately for each files\n",
    "alphaA=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    alphaA[i]=read_di(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27677d26-5b21-4a39-a77f-e24aeaa6c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alpha bandpass filter from class B\n",
    "def read_dj(i):\n",
    "    fs = 250\n",
    "    lowcut = 8.01\n",
    "    highcut = 11.99\n",
    "    alpha= butter_bandpass_filter(B[i], lowcut, highcut, fs, order=5)\n",
    "    alpha = np.mean(alpha, axis=-1)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69431ec5-79db-4309-b889-52254781acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function for alpha of classB separately for each files\n",
    "alphaB=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    alphaB[i]=read_dj(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad06eebc-8ee7-4485-83d2-03297c153b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beta bandpass filter from class A\n",
    "def read_dm(i):\n",
    "    fs = 250\n",
    "    lowcut = 12.01\n",
    "    highcut = 29.99\n",
    "    beta= butter_bandpass_filter(A[i], lowcut, highcut, fs, order=5)\n",
    "    beta = np.mean(beta, axis=-1)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7d14ea2-4477-4e6a-b4cf-94366d9b755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function for beta of classA separately for each files\n",
    "betaA=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    betaA[i]=read_dm(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5781b19-fa74-45f0-8003-da90b9f6e5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beta bandpass filter from class B\n",
    "def read_dn(i):\n",
    "    fs = 250\n",
    "    lowcut = 12.01\n",
    "    highcut = 29.99\n",
    "    beta= butter_bandpass_filter(B[i], lowcut, highcut, fs, order=5)\n",
    "    beta = np.mean(beta, axis=-1)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2456071e-0598-4661-88d3-78aa9d04ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function for beta of classB separately for each files\n",
    "betaB=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    betaB[i]=read_dn(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eea15774-293d-4ded-8db1-d29afd42d376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gamma bandpass filter from class A\n",
    "def read_dq(i):\n",
    "    fs = 250\n",
    "    lowcut = 30.01\n",
    "    highcut = 100\n",
    "    gamma= butter_bandpass_filter(A[i], lowcut, highcut, fs, order=5)\n",
    "    gamma = np.mean(gamma, axis=-1)\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a9600cb-8b0f-4c76-82a6-4f8ff33404f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function for gamma of classB separately for each files\n",
    "gammaA=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    gammaA[i]=read_dq(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4d1fe89-0d64-416f-836d-992fd6a6bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gamma bandpass filter from class B\n",
    "def read_dr(i):\n",
    "    fs = 250\n",
    "    lowcut = 30.01\n",
    "    highcut = 100\n",
    "    gamma= butter_bandpass_filter(B[i], lowcut, highcut, fs, order=5)\n",
    "    gamma = np.mean(gamma, axis=-1)\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e7c32c9-be35-453c-9daf-74803452e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function for gamma of classB separately for each files\n",
    "gammaB=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    gammaB[i]=read_dr(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "405e162f-934f-46d8-91da-4d406928c472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mean median feature function\n",
    "def calculate_mean_median_features(eeg_signals):\n",
    "    mean_median_features = []\n",
    "\n",
    "    for signal in eeg_signals:\n",
    "        segment_features = []\n",
    "\n",
    "        for segment in signal:\n",
    "            mean_feat = np.mean(segment)\n",
    "            median_feat = np.median(segment)\n",
    "            \n",
    "            segment_features.append(mean_feat)\n",
    "            segment_features.append(median_feat)\n",
    "        \n",
    "        mean_median_features.append(segment_features)\n",
    "\n",
    "    return np.array(mean_median_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f737320-90cd-4288-b99b-0aebb57a1f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#meanmedian feature of class A separately for all subjects\n",
    "meanmedianA=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    meanmedianA[i]=calculate_mean_median_features(A[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d067f70-af69-4e8e-bc78-482a7933c9a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#meanmedian feature of class B separately for all subjects\n",
    "meanmedianB=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    meanmedianB[i]=calculate_mean_median_features(B[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efaffa26-3210-4482-9239-a70b77b29974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate Hjorth parameters for each EEG segment\n",
    "def hjorth_parameters(eeg_segment):\n",
    "    activity = np.var(eeg_segment)\n",
    "    diff_signal = np.diff(eeg_segment)\n",
    "    mobility = np.var(diff_signal)\n",
    "    diff2_signal = np.diff(diff_signal)\n",
    "    complexity = np.var(diff2_signal)\n",
    "    \n",
    "    return activity, mobility, complexity\n",
    "\n",
    "# Calculate Hjorth features for all segments in the EEG signals\n",
    "def calculate_hjorth_features(eeg_signals):\n",
    "    hjorth_features = []\n",
    "\n",
    "    for signal in eeg_signals:\n",
    "        segment_features = []\n",
    "\n",
    "        for segment in signal:\n",
    "            hjorth_feats = hjorth_parameters(segment)\n",
    "            segment_features.extend(hjorth_feats)\n",
    "        \n",
    "        hjorth_features.append(segment_features)\n",
    "\n",
    "    return np.array(hjorth_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18a7e0d2-7b28-404b-82d0-69f7b1da5a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hjorth feature of class A and classB separately for all subjects\n",
    "hjorthA=[0,0,0,0,0,0,0,0]\n",
    "hjorthB=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    hjorthA[i] = calculate_hjorth_features(A[i])\n",
    "    hjorthB[i] = calculate_hjorth_features(B[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b070ef97-d035-43d0-ad92-f85fa34feb96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#shanon entrophy feature function\n",
    "def shannon_entropy(signal):\n",
    "    # Compute the histogram of the signal\n",
    "    hist, _ = np.histogram(signal, bins=256, range=(0, 256))\n",
    "    \n",
    "    # Normalize the histogram\n",
    "    hist = hist / (len(signal) * 1.0)\n",
    "    \n",
    "    # Calculate Shannon entropy\n",
    "    entropy = -np.sum([p * np.log2(p + np.finfo(float).eps) for p in hist if p > 0])\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def calculate_shannon_entropy_features(eeg_signals):\n",
    "    shannon_entropy_features = []\n",
    "\n",
    "    for signal in eeg_signals:\n",
    "        segment_features = []\n",
    "\n",
    "        for segment in signal:\n",
    "            entropy_feat = shannon_entropy(segment)\n",
    "            segment_features.append(entropy_feat)\n",
    "        \n",
    "        shannon_entropy_features.append(segment_features)\n",
    "\n",
    "    return np.array(shannon_entropy_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07dd4f28-7cc9-4fa2-90be-c8ab47e6f5b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#shanon feature of class A separately for all subjects\n",
    "shanonA=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    shanonA[i]=calculate_shannon_entropy_features(A[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35ca08a1-679c-4c4b-ba8e-9da6fad59e55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#shanon feature of class B separately for all subjects\n",
    "shanonB=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    shanonB[i]=calculate_shannon_entropy_features(B[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5cd2e2f-1486-4c29-874a-6de7048171e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#wavelet feature function\n",
    "import numpy as np\n",
    "import pywt\n",
    "\n",
    "def calculate_wavelet_features(eeg_signals, wavelet='db4', level=4):\n",
    "    wavelet_features = []\n",
    "\n",
    "    for signal in eeg_signals:\n",
    "        segment_features = []\n",
    "\n",
    "        for segment in signal:\n",
    "            # Apply discrete wavelet transform\n",
    "            coeffs = pywt.wavedec(segment, wavelet, level=level)\n",
    "            \n",
    "            # Extract the approximation and detail coefficients\n",
    "            approx = coeffs[0]\n",
    "            details = np.concatenate(coeffs[1:])\n",
    "            \n",
    "            # Calculate statistical features (mean, variance, etc.) on coefficients\n",
    "            mean = np.mean(details)\n",
    "            variance = np.var(details)\n",
    "            energy = np.sum(np.square(details))\n",
    "            \n",
    "            # Append wavelet features for this segment\n",
    "            segment_features.extend([mean, variance, energy])\n",
    "        \n",
    "        wavelet_features.append(segment_features)\n",
    "\n",
    "    return np.array(wavelet_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f358c90-452c-458f-aa08-4019710543fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#wavelet feature of class A separately for all subjects\n",
    "waveletA=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    waveletA[i] = calculate_wavelet_features(A[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6bbfc58-20af-41e3-a8f5-2ad7bb4d7297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#wavelet feature of class B separately for all subjects\n",
    "waveletB=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    waveletB[i] = calculate_wavelet_features(B[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ccb55ad-bc59-48da-8794-1b21ca098180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#skewness and kurtosis feature function\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def calculate_skewness_kurtosis_features(eeg_signals):\n",
    "    skewness_features = []\n",
    "    kurtosis_features = []\n",
    "\n",
    "    for signal in eeg_signals:\n",
    "        segment_skewness = []\n",
    "        segment_kurtosis = []\n",
    "\n",
    "        for segment in signal:\n",
    "            # Calculate skewness and kurtosis for each segment\n",
    "            skew_val = skew(segment)\n",
    "            kurtosis_val = kurtosis(segment)\n",
    "\n",
    "            segment_skewness.append(skew_val)\n",
    "            segment_kurtosis.append(kurtosis_val)\n",
    "\n",
    "        # Append skewness and kurtosis features for this signal\n",
    "        skewness_features.append(segment_skewness)\n",
    "        kurtosis_features.append(segment_kurtosis)\n",
    "\n",
    "    return np.array(skewness_features), np.array(kurtosis_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d193cd99-9388-4031-865f-f6ed7b7bfdf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#skewness,kurtosis feature of class A separately for all subjects\n",
    "skewnessA=[0,0,0,0,0,0,0,0]\n",
    "kurtosisA=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    skewnessA[i], kurtosisA[i] = calculate_skewness_kurtosis_features(A[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a82bec13-c33e-4df6-a719-ca8bebe7e9da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#skewness,kurtosis feature of class A separately for all subjects\n",
    "skewnessB=[0,0,0,0,0,0,0,0]\n",
    "kurtosisB=[0,0,0,0,0,0,0,0]\n",
    "for i in range(0,8):\n",
    "    skewnessB[i], kurtosisB[i] = calculate_skewness_kurtosis_features(B[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54070934-4eb5-496e-bcfb-e5d925bc4f58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 22)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for delta feature of class A\n",
    "deltaallA=[]\n",
    "for i in range(0,8):\n",
    "    deltaallA=np.append(deltaallA,deltaA[i]);\n",
    "deltaallA=deltaallA.reshape(575,22)\n",
    "deltaallA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80ef458d-608e-4436-9fe4-694abebc8c04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574, 22)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for delta feature of class B\n",
    "deltaallB=[]\n",
    "for i in range(0,8):\n",
    "    deltaallB=np.append(deltaallB,deltaB[i]);\n",
    "deltaallB=deltaallB.reshape(574,22)\n",
    "deltaallB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3447318f-1010-4cec-bef1-3ffb740fdce8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149, 22)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data of delta feature\n",
    "aDelta=np.append(deltaallA,deltaallB)\n",
    "aDelta=aDelta.reshape(1149,22)\n",
    "aDelta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "393ec393-0a7f-4ad8-888d-4d7e7900d775",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 22)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for theta feature of class A\n",
    "thetaallA=[]\n",
    "for i in range(0,8):\n",
    "    thetaallA=np.append(thetaallA,thetaA[i])\n",
    "thetaallA=thetaallA.reshape(575,22)\n",
    "thetaallA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b5d0aa0f-6aff-4b08-a1b2-4fe00467826e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574, 22)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for theta feature of class B\n",
    "thetaallB=[]\n",
    "for i in range(0,8):\n",
    "    thetaallB=np.append(thetaallB,thetaB[i])\n",
    "thetaallB=thetaallB.reshape(574,22)\n",
    "thetaallB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc307527-d2e2-46ed-af80-96d87e859665",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149, 22)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for theta feature\n",
    "aTheta=np.append(thetaallA,thetaallB)\n",
    "aTheta=aTheta.reshape(1149,22)\n",
    "aTheta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4f4552f7-2424-4973-b211-364512ee9a06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minTheta = np.min(aTheta, axis=1, keepdims=True)\n",
    "maxTheta = np.max(aTheta, axis=1, keepdims=True)\n",
    "aTheta = (aTheta - minTheta) / (maxTheta - minTheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "38f9f12d-d19b-4fa0-8dbb-6b2a73113335",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 22)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for alpha feature of class A\n",
    "alphaallA=[]\n",
    "for i in range(0,8):\n",
    "    alphaallA=np.append(alphaallA,alphaA[i])\n",
    "alphaallA=alphaallA.reshape(575,22)\n",
    "alphaallA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2ecd33e-d972-48ba-973c-823aadeaa95a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574, 22)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for alpha feature of class B\n",
    "alphaallB=[]\n",
    "for i in range(0,8):\n",
    "    alphaallB=np.append(alphaallB,alphaB[i])\n",
    "alphaallB=alphaallB.reshape(574,22)\n",
    "alphaallB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6fe19195-571b-4ea9-97f4-3ed2a04aa55f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149, 22)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for alpha feature\n",
    "aAlpha=np.append(alphaallA,alphaallB)\n",
    "aAlpha=aAlpha.reshape(1149,22)\n",
    "aAlpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8abcae40-39ee-4a7f-8412-a824b5c4989d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minAlpha = np.min(aAlpha, axis=1, keepdims=True)\n",
    "maxAlpha = np.max(aAlpha, axis=1, keepdims=True)\n",
    "aAlpha = (aAlpha - minAlpha) / (maxAlpha - minAlpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e0866c8-0516-4bb1-a334-6ad643d09b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 22)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for beta feature of class A\n",
    "betaallA=[]\n",
    "for i in range(0,8):\n",
    "    betaallA=np.append(betaallA,betaA[i])\n",
    "betaallA=betaallA.reshape(575,22)\n",
    "betaallA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ac61dc5a-9b3a-45dd-b2bb-c202b9bc4dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574, 22)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for beta feature of class B\n",
    "betaallB=[]\n",
    "for i in range(0,8):\n",
    "    betaallB=np.append(betaallB,betaB[i])\n",
    "betaallB=betaallB.reshape(574,22)\n",
    "betaallB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f88fd660-5819-4991-bc7b-8ecb4aa7ddea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149, 22)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for beta feature\n",
    "aBeta=np.append(betaallA,betaallB)\n",
    "aBeta=aBeta.reshape(1149,22)\n",
    "aBeta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e1866905-4612-4aa4-b90b-fd04c7697375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minBeta = np.min(aBeta, axis=1, keepdims=True)\n",
    "maxBeta = np.max(aBeta, axis=1, keepdims=True)\n",
    "aBeta = (aBeta - minBeta) / (maxBeta - minBeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2486b326-121c-4b11-91df-934521d78f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 22)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for gamma feature of class A\n",
    "gammaallA=[]\n",
    "for i in range(0,8):\n",
    "    gammaallA=np.append(gammaallA,gammaA[i])\n",
    "gammaallA=gammaallA.reshape(575,22)\n",
    "gammaallA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3213dd79-ddbf-4940-87e3-ba3d32065c00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574, 22)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for gamma feature of class B\n",
    "gammaallB=[]\n",
    "for i in range(0,8):\n",
    "    gammaallB=np.append(gammaallB,gammaB[i])\n",
    "gammaallB=gammaallB.reshape(574,22)\n",
    "gammaallB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e88386f0-2211-45d8-bcd5-436fc2819778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149, 22)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for gamma feature\n",
    "aGamma=np.append(gammaallA,gammaallB)\n",
    "aGamma=aGamma.reshape(1149,22)\n",
    "aGamma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cab23015-257a-4f26-81e8-604e8962e2ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minGamma = np.min(aGamma, axis=1, keepdims=True)\n",
    "maxGamma = np.max(aGamma, axis=1, keepdims=True)\n",
    "aGamma = (aGamma - minGamma) / (maxGamma - minGamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "73cc35e9-9b82-4d06-9993-7da5de79e698",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 44)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for meanmedian feature of class A\n",
    "meanmedianallA=[]\n",
    "for i in range(0,8):\n",
    "    meanmedianallA=np.append(meanmedianallA,meanmedianA[i])\n",
    "meanmedianallA=meanmedianallA.reshape(575,44)\n",
    "meanmedianallA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7cf8406b-edce-473a-a61b-f818c8d07774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574, 44)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for meanmedian feature of class B\n",
    "meanmedianallB=[]\n",
    "for i in range(0,8):\n",
    "    meanmedianallB=np.append(meanmedianallB,meanmedianB[i])\n",
    "meanmedianallB=meanmedianallB.reshape(574,44)\n",
    "meanmedianallB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5e199573-9e51-4658-a2d0-716af940e424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149, 44)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for meanmedian feature\n",
    "meanmedianAll=np.append(meanmedianallA,meanmedianallB)\n",
    "meanmedianAll=meanmedianAll.reshape(1149,44)\n",
    "meanmedianAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1e5c15a2-6c32-4dfe-8bd0-8f7b0d17f20e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 66)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for hjorth feature of class A\n",
    "hjorthallA=[]\n",
    "for i in range(0,8):\n",
    "    hjorthallA=np.append(hjorthallA,hjorthA[i])\n",
    "hjorthallA=hjorthallA.reshape(575,66)\n",
    "hjorthallA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "097c034e-e982-4afb-b132-cb9e9d2fbd7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574, 66)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for hjorth feature of class B\n",
    "hjorthallB=[]\n",
    "for i in range(0,8):\n",
    "    hjorthallB=np.append(hjorthallB,hjorthB[i])\n",
    "hjorthallB=hjorthallB.reshape(574,66)\n",
    "hjorthallB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a8d22c4-b6d8-40e9-8241-a497514007dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149, 66)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for hjorth feature\n",
    "hjorthAll=np.append(hjorthallA,hjorthallB)\n",
    "hjorthAll=hjorthAll.reshape(1149,66)\n",
    "hjorthAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "725f6a60-909e-4378-8538-fd4b9fd778ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 22)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for shanon feature of class A\n",
    "shanonallA=[]\n",
    "for i in range(0,8):\n",
    "    shanonallA=np.append(shanonallA,shanonA[i])\n",
    "shanonallA=shanonallA.reshape(575,22)\n",
    "shanonallA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "567ef902-1a71-456c-8d95-f8a8dd25b77e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574, 22)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for shanon feature of class B\n",
    "shanonallB=[]\n",
    "for i in range(0,8):\n",
    "    shanonallB=np.append(shanonallB,shanonB[i])\n",
    "shanonallB=shanonallB.reshape(574,22)\n",
    "shanonallB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7e58f03f-2d6c-4b49-97bc-a44ea74cbe21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149, 22)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for shanon feature\n",
    "shanonAll=np.append(shanonallA,shanonallB)\n",
    "shanonAll=shanonAll.reshape(1149,22)\n",
    "shanonAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fcc3bb86-c4ca-420d-a2fe-38c15110c10e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 66)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for wavelet feature of class A\n",
    "waveletallA=[]\n",
    "for i in range(0,8):\n",
    "    waveletallA=np.append(waveletallA,waveletA[i])\n",
    "waveletallA=waveletallA.reshape(575,66)\n",
    "waveletallA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7e7462d5-1a68-4e45-bb48-330a09081cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574, 66)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for wavelet feature of class B\n",
    "waveletallB=[]\n",
    "for i in range(0,8):\n",
    "    waveletallB=np.append(waveletallB,waveletB[i])\n",
    "waveletallB=waveletallB.reshape(574,66)\n",
    "waveletallB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b2dd81f7-13e4-4e14-bbb2-cd5d2a2b864e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149, 66)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for wavelet feature\n",
    "waveletAll=np.append(waveletallA,waveletallB)\n",
    "waveletAll=waveletAll.reshape(1149,66)\n",
    "waveletAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0653e83a-2a13-4cd7-8b76-bfc9be8b8100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minWavelet = np.min(waveletAll, axis=0, keepdims=True)\n",
    "maxWavelet = np.max(waveletAll, axis=0, keepdims=True)\n",
    "waveletAll= (waveletAll - minWavelet) / (maxWavelet - minWavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af6c0a17-e25b-4f06-a3d0-4f3d8050cb9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 22)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for skewness feature of class A\n",
    "skewnessallA=[]\n",
    "for i in range(0,8):\n",
    "    skewnessallA=np.append(skewnessallA,skewnessA[i])\n",
    "skewnessallA=skewnessallA.reshape(575,22)\n",
    "skewnessallA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b843271e-101f-48ff-8b1e-8292f8d41ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574, 22)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for skewness feature of class B\n",
    "skewnessallB=[]\n",
    "for i in range(0,8):\n",
    "    skewnessallB=np.append(skewnessallB,skewnessB[i])\n",
    "skewnessallB=skewnessallB.reshape(574,22)\n",
    "skewnessallB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b4517249-e5c4-4d12-8716-69b1387ba0ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149, 22)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for skewness feature\n",
    "skewnessAll=np.append(skewnessallA,skewnessallB)\n",
    "skewnessAll=skewnessAll.reshape(1149,22)\n",
    "skewnessAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3f47d22b-25d8-4e20-a6f4-bfaaf9f35d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 22)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for kurtosis feature of class A\n",
    "kurtosisallA=[]\n",
    "for i in range(0,8):\n",
    "    kurtosisallA=np.append(kurtosisallA,kurtosisA[i])\n",
    "kurtosisallA=kurtosisallA.reshape(575,22)\n",
    "kurtosisallA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b7539ddc-b5f1-41f2-8334-35cae010710f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574, 22)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for kurtosis feature of class B\n",
    "kurtosisallB=[]\n",
    "for i in range(0,8):\n",
    "    kurtosisallB=np.append(kurtosisallB,kurtosisB[i])\n",
    "kurtosisallB=kurtosisallB.reshape(574,22)\n",
    "kurtosisallB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba126732-ea7b-4d45-ba98-8c82254e026b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149, 22)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data for kurtosis\n",
    "kurtosisAll=np.append(kurtosisallA,kurtosisallB)\n",
    "kurtosisAll=kurtosisAll.reshape(1149,22)\n",
    "kurtosisAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ab6bc7e1-9bdc-40bc-abba-18ba454841fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149, 352)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all data \n",
    "aData = np.column_stack((aDelta, aTheta, aAlpha, aBeta, aGamma,hjorthAll,meanmedianAll,shanonAll,waveletAll,skewnessAll, kurtosisAll))\n",
    "aData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eedd03c9-e1ba-4a5a-afd9-adaccc219a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#taking an empty array for labels\n",
    "xpAll=np.empty(1149,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4480d38b-fab9-46c4-9e3a-7aecad1bb2b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking the labels 0 for class A and 1 for class B\n",
    "for i in range(0,575):\n",
    "    xpAll[i]=0\n",
    "for i in range(575,1149):\n",
    "    xpAll[i]=1\n",
    "xpAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c667c214-f0f5-45e1-95ef-805428dc8f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149, 352)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9f94d60f-8443-43b4-b7f1-9a253966423c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xpAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8adc4abc-0cf2-4be6-af45-68803ad912df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96 19]\n",
      " [42 73]]\n",
      "0.7347826086956522\n"
     ]
    }
   ],
   "source": [
    "fifth_column = aData[:, 4]\n",
    "fifth_column.shape\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(fifth_column.reshape(-1, 1),xpAll,test_size=0.2,stratify=xpAll,random_state=0)\n",
    "#train the model using knn classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "classknn=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "classknn.fit(x_train,y_train)\n",
    "y_pred_a=classknn.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm= confusion_matrix(y_test, y_pred_a)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d43c7ce6-03b7-447f-a20a-3f6cfd218681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[110   5]\n",
      " [ 43  72]]\n",
      "0.7913043478260869\n"
     ]
    }
   ],
   "source": [
    "sixth_column = aData[:, 304]\n",
    "six= sixth_column.reshape(-1, 1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split( six,xpAll,test_size=0.2,stratify=xpAll,random_state=0)\n",
    "#train the model using knn classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "classknn=KNeighborsClassifier(n_neighbors=4,metric='minkowski',p=2)\n",
    "classknn.fit(x_train,y_train)\n",
    "y_pred_b=classknn.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm= confusion_matrix(y_test, y_pred_b)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ed1f6dfe-e731-4573-809d-dcee46be269d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94 21]\n",
      " [43 72]]\n",
      "0.7217391304347827\n"
     ]
    }
   ],
   "source": [
    "seventh_column = aData[:, 295]\n",
    "seventh_column.shape\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(seventh_column.reshape(-1, 1),xpAll,test_size=0.2,stratify=xpAll,random_state=0)\n",
    "#train the model using knn classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "classknn=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "classknn.fit(x_train,y_train)\n",
    "y_pred_c=classknn.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm= confusion_matrix(y_test, y_pred_c)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "43c14fd9-0914-4f9c-8dd3-b6cbe69cf20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50 65]\n",
      " [52 63]]\n",
      "0.49130434782608695\n"
     ]
    }
   ],
   "source": [
    "eight_column = aData[:, 49]\n",
    "eight_column.shape\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(eight_column.reshape(-1, 1),xpAll,test_size=0.2,stratify=xpAll,random_state=0)\n",
    "#train the model using knn classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "classknn=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "classknn.fit(x_train,y_train)\n",
    "y_pred_d=classknn.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm= confusion_matrix(y_test, y_pred_d)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4fdda898-dae4-46e2-8a5d-c5507c1ad509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103  12]\n",
      " [ 43  72]]\n",
      "0.7608695652173914\n"
     ]
    }
   ],
   "source": [
    "first_column = aData[:, 280]\n",
    "first_column.shape\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(first_column.reshape(-1, 1),xpAll,test_size=0.2,stratify=xpAll,random_state=0)\n",
    "#train the model using knn classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "classknn=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "classknn.fit(x_train,y_train)\n",
    "y_pred_e=classknn.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm= confusion_matrix(y_test, y_pred_e)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2176fc4f-66d7-406c-ac10-10154897a264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105  10]\n",
      " [ 38  77]]\n",
      "0.7913043478260869\n"
     ]
    }
   ],
   "source": [
    "second_column = aData[:, 259]\n",
    "second_column.shape\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(second_column.reshape(-1, 1),xpAll,test_size=0.2,stratify=xpAll,random_state=0)\n",
    "#train the model using knn classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "classknn=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "classknn.fit(x_train,y_train)\n",
    "y_pred_f=classknn.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm= confusion_matrix(y_test, y_pred_f)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4c5ade59-0bbf-4463-84c1-a7f23347b211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[97 18]\n",
      " [42 73]]\n",
      "0.7391304347826086\n"
     ]
    }
   ],
   "source": [
    "third_column = aData[:, 298]\n",
    "third_column.shape\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(third_column.reshape(-1, 1),xpAll,test_size=0.2,stratify=xpAll,random_state=0)\n",
    "#train the model using knn classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "classknn=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "classknn.fit(x_train,y_train)\n",
    "y_pred_g=classknn.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm= confusion_matrix(y_test, y_pred_g)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred_g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f50fb6aa-56ba-4e8b-9077-1fd0800cdf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101  14]\n",
      " [ 40  75]]\n",
      "0.7652173913043478\n"
     ]
    }
   ],
   "source": [
    "fourth_column = aData[:, 301]\n",
    "fourth_column.shape\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(fourth_column.reshape(-1, 1),xpAll,test_size=0.2,stratify=xpAll,random_state=0)\n",
    "#train the model using knn classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "classknn=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "classknn.fit(x_train,y_train)\n",
    "y_pred_h=classknn.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm= confusion_matrix(y_test, y_pred_h)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8acb0793-3e3f-4230-997f-5962624487be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101  14]\n",
      " [ 40  75]]\n",
      "0.7652173913043478\n"
     ]
    }
   ],
   "source": [
    "ninth_column = aData[:, 126]\n",
    "ninth_column.shape\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(ninth_column.reshape(-1, 1),xpAll,test_size=0.2,stratify=xpAll,random_state=0)\n",
    "#train the model using knn classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "classknn=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "classknn.fit(x_train,y_train)\n",
    "y_pred_i=classknn.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm= confusion_matrix(y_test, y_pred_h)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a9279829-065e-4211-a5cf-1c458f9bd85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "allX=np.column_stack((y_pred_a,y_pred_b,y_pred_c,y_pred_d,y_pred_e,y_pred_f,y_pred_g,y_pred_h,y_pred_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5d2f1889-a2d8-4f01-a9d9-d4c3e15929c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230, 9)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0bba0d47-2055-4333-85e2-07e0be307a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "al=np.empty(230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "51d37527-449f-4114-a8bc-5afc9247d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,230):\n",
    "    count=0\n",
    "    countp=0\n",
    "    for j in range(0,9):\n",
    "        if(allX[i][j]==0):\n",
    "            count=count+1\n",
    "        else:\n",
    "            countp=countp+1\n",
    "    if(count>countp):\n",
    "        al[i]=0\n",
    "    else:\n",
    "        al[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "092464fe-6012-4237-b9a3-67d457b735af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230,)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "55571281-8567-4e35-a9e4-8d2599ccad04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[115   0]\n",
      " [ 46  69]]\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm= confusion_matrix(y_test, al)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,al))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "11046342-ba50-40b4-8700-643b524f62a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.preprocessing import StandardScaler\\nac=StandardScaler()\\nx_train=ac.fit_transform(x_train)\\nx_test=ac.transform(x_test)'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feataure scaling\n",
    "'''from sklearn.preprocessing import StandardScaler\n",
    "ac=StandardScaler()\n",
    "x_train=ac.fit_transform(x_train)\n",
    "x_test=ac.transform(x_test)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8666f221-792e-4973-b2ad-0728790874ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44 14]\n",
      " [22 35]]\n",
      "0.6869565217391305\n",
      "[[54  4]\n",
      " [24 33]]\n",
      "0.7565217391304347\n",
      "[[49  9]\n",
      " [21 36]]\n",
      "0.7391304347826086\n",
      "[[52  6]\n",
      " [25 32]]\n",
      "0.7304347826086957\n",
      "[[51  7]\n",
      " [24 33]]\n",
      "0.7304347826086957\n",
      "[[54  4]\n",
      " [25 32]]\n",
      "0.7478260869565218\n",
      "[[51  7]\n",
      " [23 34]]\n",
      "0.7391304347826086\n",
      "[[55  3]\n",
      " [27 30]]\n",
      "0.7391304347826086\n",
      "[[54  4]\n",
      " [25 32]]\n",
      "0.7478260869565218\n",
      "[[55  3]\n",
      " [26 31]]\n",
      "0.7478260869565218\n",
      "[[55  3]\n",
      " [26 31]]\n",
      "0.7478260869565218\n",
      "[[56  2]\n",
      " [27 30]]\n",
      "0.7478260869565218\n",
      "[[56  2]\n",
      " [25 32]]\n",
      "0.7652173913043478\n",
      "[[58  0]\n",
      " [26 31]]\n",
      "0.7739130434782608\n",
      "[[57  1]\n",
      " [25 32]]\n",
      "0.7739130434782608\n",
      "[[57  1]\n",
      " [26 31]]\n",
      "0.7652173913043478\n",
      "[[57  1]\n",
      " [25 32]]\n",
      "0.7739130434782608\n",
      "[[57  1]\n",
      " [26 31]]\n",
      "0.7652173913043478\n",
      "[[57  1]\n",
      " [26 31]]\n",
      "0.7652173913043478\n",
      "[[57  1]\n",
      " [26 31]]\n",
      "0.7652173913043478\n",
      "[[57  1]\n",
      " [26 31]]\n",
      "0.7652173913043478\n",
      "[[57  1]\n",
      " [26 31]]\n",
      "0.7652173913043478\n",
      "[[57  1]\n",
      " [26 31]]\n",
      "0.7652173913043478\n",
      "[[58  0]\n",
      " [26 31]]\n",
      "0.7739130434782608\n",
      "[[58  0]\n",
      " [25 32]]\n",
      "0.782608695652174\n",
      "[[58  0]\n",
      " [25 32]]\n",
      "0.782608695652174\n",
      "[[58  0]\n",
      " [24 33]]\n",
      "0.7913043478260869\n"
     ]
    }
   ],
   "source": [
    "for i in range(3,30):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.neighbors import KNeighborsClassifier \n",
    "    x_train,x_test,y_train,y_test=train_test_split(aData,xpAll,test_size=0.1,stratify=xpAll,random_state=0)\n",
    "    classknn=KNeighborsClassifier(n_neighbors=i,metric='minkowski',p=2)\n",
    "    classknn.fit(x_train,y_train)\n",
    "    y_pred=classknn.predict(x_test)\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "    cm= confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "622606dd-c0bd-4e25-a094-4325a184bdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(aData,xpAll,test_size=0.2,stratify=xpAll,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5e99acc7-22ee-44c7-b30e-392155339bcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model using knn classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "classknn=KNeighborsClassifier(n_neighbors=3,metric='minkowski',p=2)\n",
    "classknn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e285cb46-899b-4a2e-bb87-c07174111bf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#predicting the test data\n",
    "y_pred=classknn.predict(x_test)\n",
    "#y_pred.shape\n",
    "#y_pred=classifier.predict(y_test_n)\n",
    "#print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9cd17954-d006-4522-9ebd-b713a3eb8417",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93 22]\n",
      " [39 76]]\n",
      "0.7347826086956522\n"
     ]
    }
   ],
   "source": [
    "#checking accuracy score and confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm= confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f85ff4e5-d037-47dc-9a6f-977881c41b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa: 0.4695652173913043\n",
      "Precision: 0.7400278293135436\n",
      "Recall: 0.7347826086956522\n",
      "F1-score: 0.733325730360571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "\n",
    "# Assuming you have true labels (y_true) and predicted labels (y_pred)\n",
    "# Replace y_true and y_pred with your actual data\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred, average='weighted')  # You can change the average parameter\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred, average='weighted')  # You can change the average parameter\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # You can change the average parameter\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "# Print the results\n",
    "print(f\"Cohen's Kappa: {kappa}\")\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8e7870bf-13c7-4245-b949-afb556fe181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "mic_scores = []\n",
    "selected_features=[]\n",
    "\n",
    "acc_scores=[]\n",
    "def calculate_MIC(x, y):\n",
    "    # Calculate Pearson correlation coefficient (r) between x and y\n",
    "    r, _ = pearsonr(x, y)\n",
    "    \n",
    "    # Calculate MIC using the formula MIC = |r| * log2(n)\n",
    "    n = len(x)\n",
    "    mic = abs(r) * np.log2(n)\n",
    "    \n",
    "    return mic\n",
    "\n",
    "for i in range(0,352):\n",
    "    mic_score = calculate_MIC(aData[:, i], xpAll)\n",
    "    mic_scores.append(mic_score)\n",
    "\n",
    "\n",
    "# Sort features based on MIC scores (in descending order)\n",
    "sorted_features = np.argsort(mic_scores)[::-1]\n",
    "\n",
    "# Select the top 20 features\n",
    "for i in range(2,352):\n",
    "    top_20_features = sorted_features[:i]\n",
    "    top_20_feature_values = aData[:, top_20_features]\n",
    "    \n",
    "    x_train,x_test,y_train,y_test=train_test_split(top_20_feature_values,xpAll,test_size=0.1,stratify=xpAll,random_state=0)\n",
    "   \n",
    "    for j in range(3,20):\n",
    "        classknn=KNeighborsClassifier(n_neighbors=j,metric='minkowski',p=2)\n",
    "        classknn.fit(x_train,y_train)\n",
    "        y_pred=classknn.predict(x_test)\n",
    "        cm= confusion_matrix(y_test, y_pred)\n",
    "        acc_score=accuracy_score(y_test,y_pred)\n",
    "        acc_scores.append(acc_score)\n",
    "        #if(accuracy_score(y_test,y_pred)>0.75):\n",
    "         #   print(\"No of Feature selected and neighbour :\",i,j)\n",
    "          #  print(accuracy_score(y_test,y_pred))\n",
    "          #  print(cm)\n",
    "        \n",
    "sorted_acc_scores = np.argsort(mic_scores)[::-1]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "324dc78f-35ba-4f01-895c-c4336ebcb33d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Feature selected :219 no of neighbours: 7\n",
      "[[110   5]\n",
      " [ 45  70]]\n",
      "0.782608695652174\n"
     ]
    }
   ],
   "source": [
    "#selecting only the features which has gained highest accuracy in mic feature selection and checking accuracy score with confusion matrix\n",
    "top_20_features = sorted_features[:3]\n",
    "top_20_feature_values = aData[:, top_20_features]\n",
    "#train-test\n",
    "x_train,x_test,y_train,y_test=train_test_split(top_20_feature_values,xpAll,test_size=0.2,stratify=xpAll,random_state=0)\n",
    "#feature-scaling\n",
    "#classification\n",
    "classknn=KNeighborsClassifier(n_neighbors=6,metric='minkowski',p=2)\n",
    "classknn.fit(x_train,y_train)\n",
    "#prediction\n",
    "y_pred=classknn.predict(x_test)\n",
    "#confusion matrix\n",
    "cm= confusion_matrix(y_test, y_pred)\n",
    "print(\"No of Feature selected :219 no of neighbours: 7\")\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "95b093c7-3ec6-417e-90de-bfb177da733b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa: 0.5652173913043479\n",
      "Precision: 0.8215053763440859\n",
      "Recall: 0.782608695652174\n",
      "F1-score: 0.7758284600389864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "\n",
    "# Assuming you have true labels (y_true) and predicted labels (y_pred)\n",
    "# Replace y_true and y_pred with your actual data\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred, average='weighted')  # You can change the average parameter\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred, average='weighted')  # You can change the average parameter\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # You can change the average parameter\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "# Print the results\n",
    "print(f\"Cohen's Kappa: {kappa}\")\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\",f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
